<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Django on 宋军亮的技术博客</title>
    <link>/categories/django/</link>
    <description>Recent content in Django on 宋军亮的技术博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 02 Dec 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/django/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>正向路由与普通路由</title>
      <link>/2018/%E6%AD%A3%E5%90%91%E8%B7%AF%E7%94%B1%E4%B8%8E%E6%99%AE%E9%80%9A%E8%B7%AF%E7%94%B1/</link>
      <pubDate>Sun, 02 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/%E6%AD%A3%E5%90%91%E8%B7%AF%E7%94%B1%E4%B8%8E%E6%99%AE%E9%80%9A%E8%B7%AF%E7%94%B1/</guid>
      <description>什么是路由？ ​ URL是Web服务的入口，用户通过浏览器发送过来的任何请求，都是发送到一个指定的URL地址，然后被响应。
在项目中编写路由，就是向外暴露我们接收哪些URL的请求，除此之外的任何URL都不被处理，也没有返回。通俗地理解，不恰当的形容，URL路由是你的Web服务对外暴露的API。
django使用反向解析需要添加应用的命名空间，例如上图的 app_name = “booktest” booktest是你应用的名字 使用反向解析需要在url匹配后添加自己定义的name
反向解析传递参数空格就行，这里的2就表示需要传递的参数，booktest就是你当前的这个应用的名字，fortest2就是你需要之前定义的名字
什么是正则路由？ 在开发过程中，可能会出现限制用户访问规则的场景，那么这个时候就需要用到正则匹配，根据自己的规则去限定请求参数再进行访问。
例子：
 url(r&amp;rsquo;^index&amp;rsquo;,views.index) #默认的 url(r&amp;rsquo;^home&amp;rsquo;,views.Home.as_view()) # CBV 形式 也就是说 class
 url(r&amp;rsquo;^detail-(\d+).html&amp;rsquo;, views.detail), # 在views里 def home(request, nid, uid) 这两个参数不能调换循序
  ### # http: //www.baidu.com/detail-2-8.html 2是nid 8是uid
 url (r&amp;rsquo;^detail-(?P&amp;lt; nid&amp;gt;\d+)-(?P&amp;lt; uid&amp;gt;\d+) .html&amp;rsquo;, views.detail) #多个正则 在views里 def home(request, nid, uid) 这两个参数可以没有顺序  什么情况下使用反向解析？ 所谓反向解析就是根据命名来调到指定的页面，这里表示的是跳转到booktest模板下面的fortest2这个视图里面， 而这个fortest2正是我们定义的名字，后面的2表示需要传递过去的参数
一、urls硬编码 在反向解析和命名空间之前我们先来说说URLS硬编码，用django 开发应用的时候，可以完全是在urls.py 中硬编码配置地址,在views.py中HttpResponseRedirect()也是硬编码转向地址，当然在template 中也是一样了，这样带来一个问题，如果在urls.py 中修改了某个页面的地址（也就是说更改路由系统中对应的路由分发），那么所有的地方(views.py和template中)都要修改。问题出在硬编码，紧耦合使得在大量的模板中修改 URLs 成为富有挑战性的项目。来看下面的模板文件index.html中，我们到的链接硬编码成这样子：
&amp;lt;li&amp;gt;&amp;lt;a href=&amp;quot;/goods/index/&amp;quot;&amp;gt;url硬编码&amp;lt;/a&amp;gt;&amp;lt;/li&amp;gt;  如果使用软编码之后，无论怎么更改路由系统中的路由分发，只有对应的namespace与name属性值不变，就不必修改在views.</description>
    </item>
    
    <item>
      <title>装饰器</title>
      <link>/2018/%E8%A3%85%E9%A5%B0%E5%99%A8/</link>
      <pubDate>Wed, 18 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/%E8%A3%85%E9%A5%B0%E5%99%A8/</guid>
      <description>Kafka的消息是保存或缓存在磁盘上的，一般认为在磁盘上读写数据是会降低性能的，因为寻址会比较消耗时间，但是实际上，Kafka的特性之一就是高吞吐率。
即使是普通的服务器，Kafka也可以轻松支持每秒百万级的写入请求，超过了大部分的消息中间件，这种特性也使得Kafka在日志处理等海量数据场景广泛应用。
针对Kafka的基准测试可以参考，Apache Kafka基准测试：每秒写入2百万（在三台廉价机器上）
下面从数据写入和读取两方面分析，为什么Kafka速度这么快。
一、写入数据
Kafka会把收到的消息都写入到硬盘中，它绝对不会丢失数据。为了优化写入速度Kafka采用了两个技术， 顺序写入和MMFile 。
1、顺序写入
磁盘读写的快慢取决于你怎么使用它，也就是顺序读写或者随机读写。在顺序读写的情况下，磁盘的顺序读写速度和内存持平。
因为硬盘是机械结构，每次读写都会寻址-&amp;gt;写入，其中寻址是一个“机械动作”，它是最耗时的。所以硬盘最讨厌随机I/O，最喜欢顺序I/O。为了提高读写硬盘的速度，Kafka就是使用顺序I/O。
而且Linux对于磁盘的读写优化也比较多，包括read-ahead和write-behind，磁盘缓存等。如果在内存做这些操作的时候，一个是JAVA对象的内存开销很大，另一个是随着堆内存数据的增多，JAVA的GC时间会变得很长，使用磁盘操作有以下几个好处：
 磁盘顺序读写速度超过内存随机读写 JVM的GC效率低，内存占用大。使用磁盘可以避免这一问题 系统冷启动后，磁盘缓存依然可用  下图就示了Kafka是如何写入数据的， 每一个Partition其实都是一个文件 ，收到消息后Kafka会把数据插入到文件末尾（虚框部分）：
这种方法有一个缺陷——没有办法删除数据 ，所以Kafka是不会删除数据的，它会把所有的数据都保留下来，每个消费者（Consumer）对每个Topic都有一个offset用来表示读取到了第几条数据 。
两个消费者：
 Consumer1有两个offset分别对应Partition0、Partition1（假设每一个Topic一个Partition）； Consumer2有一个offset对应Partition2。  这个offset是由客户端SDK负责保存的，Kafka的Broker完全无视这个东西的存在；一般情况下SDK会把它保存到Zookeeper里面，所以需要给Consumer提供zookeeper的地址。
如果不删除硬盘肯定会被撑满，所以Kakfa提供了两种策略来删除数据：
 一是基于时间； 二是基于partition文件大小。  具体配置可以参看它的配置文档。
2、Memory Mapped Files
即便是顺序写入硬盘，硬盘的访问速度还是不可能追上内存。所以Kafka的数据并不是实时的写入硬盘 ，它充分利用了现代操作系统分页存储来利用内存提高I/O效率。
Memory Mapped Files(后面简称mmap)也被翻译成 内存映射文件 ，在64位操作系统中一般可以表示20G的数据文件，它的工作原理是直接利用操作系统的Page来实现文件到物理内存的直接映射。
完成映射之后你对物理内存的操作会被同步到硬盘上（操作系统在适当的时候）。
通过mmap，进程像读写硬盘一样读写内存（当然是虚拟机内存），也不必关心内存的大小有虚拟内存为我们兜底。
使用这种方式可以获取很大的I/O提升，省去了用户空间到内核空间复制的开销（调用文件的read会把数据先放到内核空间的内存中，然后再复制到用户空间的内存中。）
但也有一个很明显的缺陷——不可靠，写到mmap中的数据并没有被真正的写到硬盘，操作系统会在程序主动调用flush的时候才把数据真正的写到硬盘。
Kafka提供了一个参数——producer.type来控制是不是主动flush，如果Kafka写入到mmap之后就立即flush然后再返回Producer叫 同步 (sync)；写入mmap之后立即返回Producer不调用flush叫异步 (async)。
二、读取数据
Kafka在读取磁盘时做了哪些优化？
2、基于sendfile实现Zero Copy
传统模式下，当需要对一个文件进行传输的时候，其具体流程细节如下：
 调用read函数，文件数据被copy到内核缓冲区 read函数返回，文件数据从内核缓冲区copy到用户缓冲区 write函数调用，将文件数据从用户缓冲区copy到内核与socket相关的缓冲区。 数据从socket缓冲区copy到相关协议引擎。  以上细节是传统read/write方式进行网络文件传输的方式，我们可以看到，在这个过程当中，文件数据实际上是经过了四次copy操作：
硬盘—&amp;gt;内核buf—&amp;gt;用户buf—&amp;gt;socket相关缓冲区—&amp;gt;协议引擎
而sendfile系统调用则提供了一种减少以上多次copy，提升文件传输性能的方法。
在内核版本2.1中，引入了sendfile系统调用，以简化网络上和两个本地文件之间的数据传输。sendfile的引入不仅减少了数据复制，还减少了上下文切换。
sendfile(socket, file, len);</description>
    </item>
    
    <item>
      <title>分页优化</title>
      <link>/2018/%E5%88%86%E9%A1%B5%E4%BC%98%E5%8C%96/</link>
      <pubDate>Wed, 14 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/%E5%88%86%E9%A1%B5%E4%BC%98%E5%8C%96/</guid>
      <description>使用合理的分页方式以提高分页的效率
select id,name from product limit 866613, 20
使用上述SQL语句做分页的时候，可能有人会发现，随着表数据量的增加，直接使用limit分页查询会越来越慢。
优化的方法如下：可以取前一页的最大行数的id，然后根据这个最大的id来限制下一页的起点。比如此列中，上一页最大的id是866612。SQL可以采用如下的写法：
select id,name from product where id&amp;gt; 866612 limit 20
△分段查询 在一些用户选择页面中，可能一些用户选择的时间范围过大，造成查询缓慢。主要的原因是扫描行数过多。这个时候可以通过程序，分段进行查询，循环遍历，将结果合并处理进行展示。
扫描的行数成百万级以上的时候就可以使用分段查询</description>
    </item>
    
    <item>
      <title>django密码加密</title>
      <link>/2017/django%E5%AF%86%E7%A0%81%E5%8A%A0%E5%AF%86/</link>
      <pubDate>Sat, 09 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/django%E5%AF%86%E7%A0%81%E5%8A%A0%E5%AF%86/</guid>
      <description>python的Django框架自带了一套加密方法: make_password( ),具体作用如下:
&amp;gt;&amp;gt;&amp;gt; from django.contrib.auth.hashers import make_password, check_password &amp;gt;&amp;gt;&amp;gt; make_password(&amp;quot;www.baidu.com&amp;quot;, None, &#39;pbkdf2_sha1&#39;)  参1: 加密的密码,参2: 任意字符串(用于固定生成的字符串,不能为空) 参3: 加密方式
得到的是一串随机字符串,并且每次生成都不一样
&amp;gt;&amp;gt;&amp;gt; make_password(&amp;quot;abcdef&amp;quot;, None, &#39;pbkdf2_sha256&#39;) == make_password(&amp;quot;abcdef&amp;quot;, None,&#39;pbkdf2_sha256&#39;) False  这时候如果需要验证密码比较是否正确就需要用check_password( ),具体如下:
&amp;gt;&amp;gt;&amp;gt; text = &amp;quot;www.baidu.com&amp;quot; &amp;gt;&amp;gt;&amp;gt; passwd = make_password(text, None, &#39;pbkdf2_sha1&#39;) &amp;gt;&amp;gt;&amp;gt; print passwd pbkdf2_sha112000xzMLhCNvQbb8$i1XDnJIpb/cRRGRX2x7Ym74RNfPRCUp5pbU6Sn+V3J0= &amp;gt;&amp;gt;&amp;gt; ret = check_password(text, passwd) &amp;gt;&amp;gt;&amp;gt; print(ret) True  如果你不想每次都生成不同的密文，可以把make_password的第二个函数给一个固定的字符串,如下:
&amp;gt;&amp;gt;&amp;gt; make_password(text,&amp;quot;a&amp;quot;,&#39;pbkdf2_sha1&#39;) u&#39;pbkdf2_sha112000a5HkIPczRZGSTKUBa5uzZmRuAWdp2Qe6Oemhdasvzv4Q=&#39; &amp;gt;&amp;gt;&amp;gt; make_password(text,&amp;quot;a&amp;quot;,&#39;pbkdf2_sha1&#39;) u′pbkdf2_sha112000a5HkIPczRZGSTKUBa5uzZmRuAWdp2Qe6Oemhdasvzv4Q=&#39;  </description>
    </item>
    
    <item>
      <title>挂起我的服务器screen</title>
      <link>/2016/%E6%8C%82%E8%B5%B7%E6%88%91%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%99%A8screen/</link>
      <pubDate>Fri, 21 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>/2016/%E6%8C%82%E8%B5%B7%E6%88%91%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%99%A8screen/</guid>
      <description>你是不是经常需要 SSH 或者 telent 远程登录到 Linux 服务器？你是不是经常为一些长时间运行的任务而头疼，比如系统备份、ftp 传输等等。通常情况下我们都是为每一个这样的任务开一个远程终端窗口，因为他们执行的时间太长了。必须等待它执行完毕，在此期间可不能关掉窗口或者断开连接，否则这个任务就会被杀掉，一切半途而废了。那么究竟是什么到导致的呢？
==元凶：SIGHUP 信号== 让我们来看看为什么关掉窗口/断开连接会使得正在运行的程序死掉。
在Linux/Unix中，有这样几个概念：
 进程组（process group）：一个或多个进程的集合，每一个进程组有唯一一个进程组ID，即进程组长进程的ID。 会话期（session）：一个或多个进程组的集合，有唯一一个会话期首进程（session leader）。会话期ID为首进程的ID。 会话期可以有一个单独的控制终端（controlling terminal）。与控制终端连接的会话期首进程叫做控制进程（controlling process）。当前与终端交互的进程称为前台进程组。其余进程组称为后台进程组。  根据POSIX.1定义：
 挂断信号（SIGHUP）默认的动作是终止程序。 当终端接口检测到网络连接断开，将挂断信号发送给控制进程（会话期首进程）。 如果会话期首进程终止，则该信号发送到该会话期前台进程组。 一个进程退出导致一个孤儿进程组中产生时，如果任意一个孤儿进程组进程处于STOP状态，发送SIGHUP和SIGCONT信号到该进程组中所有进程。  因此当网络断开或终端窗口关闭后，控制进程收到SIGHUP信号退出，会导致该会话期内其他进程退出。
我们来看一个例子。打开两个SSH终端窗口，在其中一个运行top命令。
`[root@tivf09 root]# top`  在另一个终端窗口，找到top的进程ID为5180，其父进程ID为5128，即登录shell。
`[root@tivf09 root]# ps -ef|grep top``root 5180 5128 0 01:03 pts/0 00:00:02 top``root 5857 3672 0 01:12 pts/2 00:00:00 grep top`  使用pstree命令可以更清楚地看到这个关系：
`[root@tivf09 root]# pstree -H 5180|grep top``|-sshd-+-sshd---bash---top`  使用ps-xj命令可以看到，登录shell（PID 5128）和top在同一个会话期，shell为会话期首进程，所在进程组PGID为5128，top所在进程组PGID为5180，为前台进程组。
`[root@tivf09 root]# ps -xj|grep 5128`` ``5126 5128 5128 5128 pts/0 5180 S 0 0:00 -bash`` ``5128 5180 5180 5128 pts/0 5180 S 0 0:50 top`` ``3672 18095 18094 3672 pts/2 18094 S 0 0:00 grep 5128`  关闭第一个SSH窗口，在另一个窗口中可以看到top也被杀掉了。</description>
    </item>
    
    <item>
      <title>排序算法</title>
      <link>/2016/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/</link>
      <pubDate>Thu, 20 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>/2016/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/</guid>
      <description>  Python中排序分为：  插入排序： 直接插入排序 希尔排序 选择排序： 简单选择排序 堆排序 交换排序： 快速排序 冒泡排序 归并排序 基数排序 </description>
    </item>
    
  </channel>
</rss>